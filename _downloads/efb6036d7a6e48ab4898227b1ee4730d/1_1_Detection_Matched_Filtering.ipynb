{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 1.1 Template Matching Detection\n\n## Overview\nThis part of the code is designed to prepare templates for seismic event detection. \nIt accomplishes this by reading event times from an event catalog and extracting the corresponding data from continuous seismic recordings. The primary aim is to save these extracted templates for each station, enabling their use in subsequent matched filtering analysis.\n\n## Methodology\n- **Data Preparation**:\n    - The script reads continuous waveform data, that should be downloaded using the script in \n    \"ToC2ME_WorkedExamples\" directory. In this example the data will be downloaded on the fly\n    - A band-pass filter is applied to the continuous data, targeting a frequency range of 1-200 Hz.\n    - Event times from the catalog are utilized to extract corresponding templates, which are saved for each station.\n    - Each extracted template is normalized to ensure a maximum absolute value of 1.\n\n- **Output**:\n    - Each template is stored as a NumPy file in a specified output directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport json\nimport pandas as pd\nimport requests\n\nimport obspy\nfrom obspy.core import UTCDateTime\nfrom obspy import read\nfrom obspy.clients.fdsn import Client\n# For tracking time\nfrom time import time\nfrom datetime import datetime\n\nfrom fracspy.detection.matched_filtering import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Constants\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "target_month = 11\ntarget_day = 22\ntarget_hour = 1\n\nNUMBER_OF_TEMPLATES =20\n\nTEMPLATE_DURATION = 4      #: Duration of each template (in seconds)\nCORRELATION_THRESHOLD = 0.75         #: Define a threshold for maximum correlation to filter significant results\nWINDOW_STEP = 1                     #: Step size for the moving window in seconds\n\n\nstation_list = [str(stationID) for stationID in range(1120,1130)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Read continuous data and previously extracted templates\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load event catalogue\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Load the short event catalog from an Excel file.\n# Provide URL for the catalogue\ncatalogue_url = 'https://zenodo.org/records/6826326/files/ToC2ME_catalog.xlsx?download=1'\n# Download the file content directly into a DataFrame\nresponse = requests.get(catalogue_url)\n# Check if the request was successful\nif response.status_code == 200:\n    # Load the Excel data directly from the response content\n    df = pd.read_excel(pd.io.excel.ExcelFile(response.content))\n    print(\"Data was successfully downloaded and loaded into the DataFrame.\")\nelse:\n    print(\"Failed to download the file. Status code:\", response.status_code)\n    exit()  # Exit if the download failed\n# Filter the DataFrame based on the specified month and day\ncatalog = df[(df['Month'] == target_month) & (df['Day'] == target_day) & (df['Hour'] == target_hour)]\n\n# Select the largest 20 magnitude events from the catalog.\ncatalog = catalog.sort_values(by=['Magnitude'], ascending=False).head(NUMBER_OF_TEMPLATES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load continuous seismic data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define client\nclient = Client(\"IRIS\")\n# Starting time close to selected event #1\nt1 = UTCDateTime(\"2016-11-22T01:00:00\")\n# Add more time for inventory grabbing\nt2 = UTCDateTime(\"2016-11-22T02:04:00\")\nprint(f\"Time range: {t1} - {t2}\")\n\n# Get inventory\ninventory = client.get_stations(network=\"5B\", station=\"*\",\n                                starttime=t1,\n                                endtime=t2)\n# Get station codes\nstation_info = inventory.networks[0].stations\nstation_codes = []\nfor station in station_info:\n    station_codes.append(station.code)\n\ntr_data = []\nstart_time = time()\ni = 0\nfor st_code in station_codes:\n    if st_code in station_list:\n        st = client.get_waveforms(network=\"5B\", \n                                  station=st_code, \n                                  location=\"00\",\n                                  channel=\"DHZ\", \n                                  starttime=t1, \n                                  endtime=t2)\n        tr_data.append(st[0].data)\nend_time = time()\nprint(f\"Done! Loading time: {end_time - start_time} seconds\")\n\n# Create a numpy array for data\ntrace_array = np.array(tr_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Build Station Templates\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dt = st[0].stats.delta\nt = np.arange(t1, t2+dt, dt).astype(datetime)\n\nTEMPLATE_LENGTH = int(TEMPLATE_DURATION * (1/dt) + 1)  #: Total number of samples per template\n\ntemplates = np.zeros([trace_array.shape[0],NUMBER_OF_TEMPLATES,TEMPLATE_LENGTH])\n# Loop over receivers\nfor tr_i, trace in enumerate(trace_array):\n    i=0\n    for index, row in catalog.iterrows():\n        # Create the extraction time based on the event details in the catalog.\n        event_time_str = f\"2016-{int(row['Month']):02d}-{int(row['Day']):02d}T\" \\\n                         f\"{int(row['Hour']):02d}:{int(row['Minute']):02d}:\" \\\n                         f\"{int(row['Second']):02d}.000000Z\"\n        event_time = obspy.UTCDateTime(event_time_str)\n        # Matching catalogue to trace time\n        event_time_index = np.where(t==event_time)[0][0]\n        # Trace Segment\n        template = trace[event_time_index:event_time_index+TEMPLATE_LENGTH]\n        template /=  np.max(np.abs(template))\n        templates[tr_i,i] = template\n        i+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plotting\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Select one template to plot; here we take the first one as an example\nexample_template = templates[0][0]\n\n# Generate a time axis for the template\ntime_axis = np.linspace(0, TEMPLATE_DURATION, len(example_template))\n\n# Plotting the example template\nplt.figure(figsize=(12, 6))\nplt.plot(time_axis, example_template, label='Event Template', color='b')\nplt.title(f'Seismic Event Template for Station: {station_list[0]}')\nplt.xlabel('Time (seconds)')\nplt.ylabel('Normalized Amplitude')\nplt.grid()\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Matched Filtering (Cross-correlation)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results_dict = [] \nfor tr_index,trace in enumerate(trace_array):  \n    station_name = station_list[tr_index]\n    print(f\"Using Station: {station_name}\")\n\n    # Filter template paths to get only those that match the current station's templates\n    trace_templates = templates[tr_index]\n\n    # Ensure we have corresponding templates for the current station\n    if len(trace_templates)==0:\n        print(f\"No template files found for station: {station_name}\")\n        continue  # Skip to the next data file if no templates are available\n\n    # Call the function to perform matched filtering\n    trace_results_dict = matched_filtering(trace,\n                                             trace_templates, \n                                             dt,\n                                             station_name,\n                                             t1,\n                                             TEMPLATE_DURATION,\n                                             TEMPLATE_LENGTH,\n                                             WINDOW_STEP,\n                                             CORRELATION_THRESHOLD)\n    \n    results_dict.append(trace_results_dict)    \n    # Print the number of detected events for the current station\n    print(f\"Number of detected events for {station_name}: {len(trace_results_dict)}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plotting Detected Events\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if trace_results_dict:  # Check if there are detected events\n    # Select the first detected event for demonstration\n    first_event_time = list(trace_results_dict.keys())[0]  # Using the first event's start time\n    event_info = trace_results_dict[first_event_time]\n\n    # Calculate the start and end time for the event\n    event_start_time = obspy.UTCDateTime(first_event_time)\n    event_end_time = event_start_time + TEMPLATE_DURATION\n\n    event_start_time_index = np.where(t==event_start_time)[0][0]\n    event_end_time_index = np.where(t==event_end_time)[0][0]\n    \n    # Extract the segment of continuous data corresponding to the detected event\n    event_data_array = trace_array[0][event_start_time_index:event_end_time_index]\n    event_data_array /= np.max(np.abs(event_data_array))  # Normalize to max absolute value of 1\n\n    # Create a time axis for plotting\n    time_axis = np.linspace(0, TEMPLATE_DURATION, len(event_data_array))\n\n    # Plotting the detected event and its correlation value\n    plt.figure(figsize=(12, 6))\n    plt.plot(time_axis, event_data_array, label='Detected Event', color='g')\n    plt.title(f'Detected Event at {station_list[tr_index]}')\n    plt.xlabel('Time (seconds)')\n    plt.ylabel('Normalized Amplitude')\n    plt.legend()\n    plt.grid()\n    plt.show()\nelse:\n    print(f\"No events detected for {station_list[tr_index]}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Associate Detected Events Across Stations\nThis part of the code loads the results of detected seismic events saved in JSON format, \nassociates detected events across different stations based on their timestamps, and saves \nthe results containing only events detected  by at least two stations within a specified time window.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Call the function to associate detected events\nassociated_events = associate_detected_events(results_dict,time_window=4,num_station=3)\n\n# Print out the associated events for review\nprint(f\"\\nNumber of associated detected events: {len(associated_events)}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}