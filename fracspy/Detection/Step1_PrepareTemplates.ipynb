{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94c6330f",
   "metadata": {},
   "source": [
    "# Template Extraction from Continuous Seismic Data\n",
    "\n",
    "## Overview\n",
    "This script extracts templates from continuous seismic waveform data based on selected events from a short event catalog. It processes continuous data files to isolate signals corresponding to the largest magnitude events, creating templates that can be used for further analysis, such as matched filtering.\n",
    "\n",
    "## Methodology\n",
    "1. **Load Data**: \n",
    "   - The script reads continuous waveform data from a specified directory and loads a short event catalog from an Excel file.\n",
    "\n",
    "2. **Select Events**: \n",
    "   - It selects the largest 20 magnitude events from the catalog, sorting the events by their magnitude.\n",
    "\n",
    "3. **Process Continuous Data**:\n",
    "   - For each continuous data file, the script reads the data stream, applies a band-pass filter (1-200 Hz), and extracts templates based on the event details in the catalog.\n",
    "   - For each event, it creates a time window corresponding to the events origin time, trims the stream to this window, normalizes the extracted data, and appends the data as a template.\n",
    "\n",
    "4. **Save Templates**: \n",
    "   - The extracted templates are saved as numpy (.npy) files in a specified directory structure based on the event details.\n",
    "\n",
    "## Key Parameters\n",
    "- **NUMBER_OF_TEMPLATES**: Number of templates to extract (default: 20).\n",
    "- **TEMPLATE_DURATION**: Duration of each template in seconds (default: 4 seconds).\n",
    "\n",
    "## Dependencies\n",
    "This script requires the following Python libraries:\n",
    "- `obspy` for seismic data processing\n",
    "- `numpy` for numerical operations\n",
    "- `pandas` for data handling\n",
    "- `glob` and `os` for file operations\n",
    "\n",
    "Make sure to have these libraries installed in your Python environment before running the script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7aabf54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Data File: data/1177.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1114.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1158.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1130.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1178.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1113.5B.mseed, Number of Events to Process: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_533780/3650308932.py:59: RuntimeWarning: invalid value encountered in true_divide\n",
      "  data_array /= np.max(np.abs(data_array))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Data File: data/1155.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1159.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1171.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1187.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1188.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1215.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1138.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1127.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1210.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1175.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1192.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1167.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1131.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1122.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1186.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1107.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1140.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1160.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1141.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1119.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1147.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1157.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1116.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1148.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1120.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1108.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1193.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1136.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1182.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1135.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1126.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1190.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1146.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1152.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1180.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1111.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1150.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1133.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1194.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1112.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1209.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1161.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1109.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1149.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1123.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1139.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1128.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1121.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1125.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1165.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1132.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1168.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1179.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1118.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1143.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1129.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1153.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1151.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1142.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1166.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1174.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1176.5B.mseed, Number of Events to Process: 20\n",
      "Processing Data File: data/1164.5B.mseed, Number of Events to Process: 20\n"
     ]
    }
   ],
   "source": [
    "import obspy\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Constants\n",
    "NUMBER_OF_TEMPLATES = 20  # Number of templates to extract\n",
    "TEMPLATE_DURATION = 4      # Duration of each template (in seconds)\n",
    "\n",
    "# Read continuous waveform data from the specified directory\n",
    "data_paths = glob.glob('data/*.mseed')\n",
    "\n",
    "# Load the short event catalog from an Excel file\n",
    "catalog = pd.read_excel('Catalog_JGR_OneDay.xlsx')\n",
    "\n",
    "# Select the largest 20 magnitude events from the catalog\n",
    "catalog = catalog.sort_values(by=['Magnitude Mw'], ascending=False).head(NUMBER_OF_TEMPLATES)\n",
    "\n",
    "# Loop over each continuous data file (currently set to process the first file only)\n",
    "for data_file in data_paths:  # Adjust to iterate over multiple files if necessary\n",
    "    # Initialize a list to store station templates\n",
    "    station_templates = []\n",
    "    \n",
    "    # Print the current data file being processed and the number of events to process\n",
    "    print(f\"Processing Data File: {data_file}, Number of Events to Process: {len(catalog)}\")\n",
    "\n",
    "    # Loop through the selected events in the catalog\n",
    "    for index in range(len(catalog)):\n",
    "        # Read the continuous data stream\n",
    "        st = obspy.read(data_file)\n",
    "        \n",
    "        # Apply a band-pass filter to the data (1-200 Hz)\n",
    "        st.filter('bandpass', freqmin=1, freqmax=200, corners=4, zerophase=False)\n",
    "        \n",
    "        # Extract the station name from the stream\n",
    "        station_name = st[0].stats.station\n",
    "        \n",
    "        \n",
    "\n",
    "        # Create the extraction time based on the event details in the catalog\n",
    "        event_time_str = f\"2016-{int(catalog.iloc[index]['Month']):02d}-{int(catalog.iloc[index]['Day']):02d}T{int(catalog.iloc[index]['Hour']):02d}:{int(catalog.iloc[index]['Minute']):02d}:{int(catalog.iloc[index]['Second']):02d}.000000Z\"\n",
    "        event_time = obspy.UTCDateTime(event_time_str)\n",
    "\n",
    "        # Formulate the file name for storing the templates\n",
    "        file_name = f\"EV{int(catalog.iloc[index]['Month']):02d}{int(catalog.iloc[index]['Day']):02d}_{int(catalog.iloc[index]['Hour']):02d}{int(catalog.iloc[index]['Minute']):02d}{int(catalog.iloc[index]['Second']):02d}\"\n",
    "\n",
    "        # Create a directory to save the templates if it doesn't exist\n",
    "        output_dir = f\"database/{file_name}\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Trim the stream to the specified time window for the template\n",
    "        st_trimmed = st.trim(event_time, event_time + TEMPLATE_DURATION)\n",
    "\n",
    "        # Extract data from the first channel of the stream\n",
    "        data_array = st_trimmed[0].data\n",
    "        \n",
    "        # Normalize the data to have a maximum absolute value of 1\n",
    "        data_array /= np.max(np.abs(data_array))\n",
    "        \n",
    "        # Append the station data to the list of templates\n",
    "        station_templates.append(data_array)\n",
    "\n",
    "    # Save the array of station templates to a .npy file\n",
    "    np.save(os.path.join(output_dir, station_name), station_templates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1af1af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DASDL",
   "language": "python",
   "name": "dasdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
